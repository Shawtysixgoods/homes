{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60704256",
   "metadata": {},
   "source": [
    "Задание 1: Три потока для обработки списка чисел"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e49f6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Задание 1: Обработка списка в трех потоках ---\n",
      "[Поток 1] Начало заполнения списка...\n",
      "[Поток 2] Ожидание заполнения списка для расчета суммы...\n",
      "[Поток 3] Ожидание заполнения списка для расчета среднего арифметического...\n",
      "[Поток 1] Список заполнен 20 случайными числами.\n",
      "[Поток 3] Среднеарифметическое значение в списке: 56.30\n",
      "[Поток 2] Сумма элементов списка: 1126\n",
      "\n",
      "--- Итоговые результаты (после завершения всех потоков) ---\n",
      "Сгенерированный список: [62, 64, 68, 44, 29, 22, 2, 47, 99, 57, 60, 68, 73, 79, 68, 34, 59, 99, 18, 74]\n",
      "Итоговая сумма (пересчет в основном потоке): 1126\n",
      "Итоговое среднее (пересчет в основном потоке): 56.30\n",
      "--- Задание 1 Завершено ---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Задание 1: Три потока для обработки списка чисел\n",
    "import threading\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Глобальные переменные и объекты синхронизации\n",
    "data_list = []\n",
    "list_filled_event = threading.Event() # Событие для сигнализации о заполнении списка\n",
    "lock = threading.Lock() # Блокировка для безопасного доступа к data_list (хотя здесь не строго нужна для чтения после заполнения)\n",
    "\n",
    "# --- Функции для потоков ---\n",
    "def fill_list(count: int, min_val: int, max_val: int):\n",
    "    \"\"\"\n",
    "    Первый поток: заполняет список случайными числами.\n",
    "    \"\"\"\n",
    "    global data_list\n",
    "    print(\"[Поток 1] Начало заполнения списка...\")\n",
    "    for _ in range(count):\n",
    "        data_list.append(random.randint(min_val, max_val))\n",
    "        time.sleep(0.01) # Небольшая имитация работы\n",
    "    print(f\"[Поток 1] Список заполнен {len(data_list)} случайными числами.\")\n",
    "    list_filled_event.set() # Сигнализируем, что список заполнен\n",
    "\n",
    "def calculate_sum():\n",
    "    \"\"\"\n",
    "    Второй поток (в задании указано как \"первый\" из двух ожидающих):\n",
    "    ожидает заполнения и вычисляет сумму элементов.\n",
    "    \"\"\"\n",
    "    print(\"[Поток 2] Ожидание заполнения списка для расчета суммы...\")\n",
    "    list_filled_event.wait() # Ждем события\n",
    "\n",
    "    # Блокировка здесь не обязательна, если список больше не изменяется после события,\n",
    "    # но для демонстрации безопасного доступа можно использовать:\n",
    "    # with lock:\n",
    "    #     local_list_copy = list(data_list) # Работаем с копией для избежания гонок, если бы список еще мог меняться\n",
    "    # current_sum = sum(local_list_copy)\n",
    "\n",
    "    current_sum = sum(data_list) # Список уже не должен меняться\n",
    "    print(f\"[Поток 2] Сумма элементов списка: {current_sum}\")\n",
    "    return current_sum\n",
    "\n",
    "def calculate_average():\n",
    "    \"\"\"\n",
    "    Третий поток (в задании указано как \"второй\" из двух ожидающих):\n",
    "    ожидает заполнения и вычисляет среднеарифметическое.\n",
    "    \"\"\"\n",
    "    print(\"[Поток 3] Ожидание заполнения списка для расчета среднего арифметического...\")\n",
    "    list_filled_event.wait() # Ждем события\n",
    "    \n",
    "    if not data_list:\n",
    "        average = 0\n",
    "        print(\"[Поток 3] Список пуст, среднее арифметическое: 0\")\n",
    "    else:\n",
    "        average = sum(data_list) / len(data_list)\n",
    "        print(f\"[Поток 3] Среднеарифметическое значение в списке: {average:.2f}\")\n",
    "    return average\n",
    "\n",
    "# --- Основная часть Задания 1 ---\n",
    "def run_task1():\n",
    "    print(\"--- Задание 1: Обработка списка в трех потоках ---\")\n",
    "\n",
    "    # Параметры для генерации списка\n",
    "    num_elements = 20\n",
    "    min_value = 1\n",
    "    max_value = 100\n",
    "\n",
    "    # Создаем потоки\n",
    "    thread_filler = threading.Thread(target=fill_list, args=(num_elements, min_value, max_value))\n",
    "    thread_summer = threading.Thread(target=calculate_sum)\n",
    "    thread_averager = threading.Thread(target=calculate_average)\n",
    "\n",
    "    # Запускаем потоки\n",
    "    # Сначала поток-заполнитель\n",
    "    thread_filler.start()\n",
    "    # Затем потоки-обработчики, которые будут ждать события\n",
    "    thread_summer.start()\n",
    "    thread_averager.start()\n",
    "\n",
    "    # Ожидаем завершения всех потоков\n",
    "    thread_filler.join()\n",
    "    thread_summer.join() # Результаты их работы будут выведены из самих потоков\n",
    "    thread_averager.join()\n",
    "\n",
    "    # Вывод финальных результатов (список уже глобальный и заполнен)\n",
    "    # Результаты суммы и среднего уже выведены потоками, но можно продублировать или получить их через return,\n",
    "    # если бы функции потоков возвращали значения и мы их как-то собирали (например, через очередь или атрибуты объекта).\n",
    "    # В данном задании требуется вывод на экран из потоков.\n",
    "    \n",
    "    print(\"\\n--- Итоговые результаты (после завершения всех потоков) ---\")\n",
    "    print(f\"Сгенерированный список: {data_list}\")\n",
    "    # Сумма и среднее уже были выведены ранее соответствующими потоками.\n",
    "    # Если нужно получить их здесь, функции calculate_sum и calculate_average\n",
    "    # должны были бы возвращать значения, а мы бы их где-то сохранили.\n",
    "    # Для простоты, как в задании, ограничимся выводом из потоков.\n",
    "    \n",
    "    # Пересчитаем для демонстрации, если нужно именно в основном потоке после всего\n",
    "    if data_list:\n",
    "        final_sum = sum(data_list)\n",
    "        final_avg = sum(data_list) / len(data_list)\n",
    "        print(f\"Итоговая сумма (пересчет в основном потоке): {final_sum}\")\n",
    "        print(f\"Итоговое среднее (пересчет в основном потоке): {final_avg:.2f}\")\n",
    "    else:\n",
    "        print(\"Список остался пустым.\")\n",
    "\n",
    "    print(\"--- Задание 1 Завершено ---\\n\")\n",
    "\n",
    "run_task1() # Раскомментируйте для запуска"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be8c4d8",
   "metadata": {},
   "source": [
    "Задание 2: Обработка чисел из файла в трех потоках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45e84589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Задание 2: Обработка файла в трех потоках ---\n",
      "[Поток 1 Запись Файла] Начало записи случайных чисел в файл 'library_books.json'...\n",
      "[Поток 2 Простые Числа] Ожидание готовности файла 'library_books.json'...\n",
      "[Поток 3 Факториалы] Ожидание готовности файла 'library_books.json'...\n",
      "[Поток 1 Запись Файла] Файл 'library_books.json' заполнен 15 числами.\n",
      "[Поток 2 Простые Числа] Файл 'library_books.json' готов. Начинаю поиск простых чисел.\n",
      "[Поток 2 Простые Числа] Найдено 7 простых чисел. Результаты в 'primes_library_books.json'.\n",
      "[Поток 3 Факториалы] Файл 'library_books.json' готов. Начинаю расчет факториалов.\n",
      "[Поток 3 Факториалы] Вычислено 14 факториалов. Результаты в 'factorials_library_books.json'.\n",
      "\n",
      "--- Статистика выполненных операций ---\n",
      "Numbers generated: 15\n",
      "Primes found: 7\n",
      "Factorials calculated: 14\n",
      "Numbers processed by primes thread: 15\n",
      "Numbers processed by factorials thread: 15\n",
      "Factorial skipped large negative: 1\n",
      "\n",
      "Содержимое исходного файла 'library_books.json':\n",
      "9\n",
      "16\n",
      "7\n",
      "17\n",
      "19\n",
      "17\n",
      "1\n",
      "12\n",
      "16\n",
      "8\n",
      "1\n",
      "13\n",
      "11\n",
      "5\n",
      "21\n",
      "\n",
      "\n",
      "Содержимое файла с простыми числами 'primes_library_books.json':\n",
      "7\n",
      "17\n",
      "19\n",
      "17\n",
      "13\n",
      "11\n",
      "5\n",
      "\n",
      "\n",
      "Содержимое файла с факториалами 'factorials_library_books.json':\n",
      "Факториал числа 9 = 362880\n",
      "Факториал числа 16 = 20922789888000\n",
      "Факториал числа 7 = 5040\n",
      "Факториал числа 17 = 355687428096000\n",
      "Факториал числа 19 = 121645100408832000\n",
      "Факториал числа 17 = 355687428096000\n",
      "Факториал числа 1 = 1\n",
      "Факториал числа 12 = 479001600\n",
      "Факториал числа 16 = 20922789888000\n",
      "Факториал числа 8 = 40320\n",
      "Факториал числа 1 = 1\n",
      "Факториал числа 13 = 6227020800\n",
      "Факториал числа 11 = 39916800\n",
      "Факториал числа 5 = 120\n",
      "Факториал числа 21 не вычислен (слишком большое или отрицательное).\n",
      "\n",
      "--- Задание 2 Завершено ---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Задание 2: Обработка чисел из файла в трех потоках\n",
    "import threading\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "\n",
    "# Глобальные объекты синхронизации\n",
    "file_ready_event = threading.Event()\n",
    "# Блокировки для записи в файлы результатов (если несколько потоков пишут в один файл)\n",
    "# В данном случае каждый поток пишет в свой файл, поэтому явные блокировки для записи файла могут не понадобиться,\n",
    "# но если бы была общая статистика или логи, то они были бы нужны.\n",
    "# lock_prime_results = threading.Lock()\n",
    "# lock_factorial_results = threading.Lock()\n",
    "# lock_stats = threading.Lock() # Для обновления общей статистики\n",
    "\n",
    "# --- Вспомогательные функции ---\n",
    "def is_prime(n: int) -> bool:\n",
    "    \"\"\"Проверяет, является ли число простым.\"\"\"\n",
    "    if n < 2:\n",
    "        return False\n",
    "    for i in range(2, int(math.sqrt(n)) + 1):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def factorial(n: int) -> int:\n",
    "    \"\"\"Вычисляет факториал числа.\"\"\"\n",
    "    if n < 0:\n",
    "        raise ValueError(\"Факториал не определен для отрицательных чисел\")\n",
    "    return math.factorial(n)\n",
    "\n",
    "# --- Функции для потоков ---\n",
    "def fill_file_with_numbers(filepath: str, count: int, min_val: int, max_val: int):\n",
    "    \"\"\"\n",
    "    Первый поток: заполняет файл случайными числами.\n",
    "    \"\"\"\n",
    "    global operations_stats\n",
    "    print(f\"[Поток 1 Запись Файла] Начало записи случайных чисел в файл '{filepath}'...\")\n",
    "    numbers_written = 0\n",
    "    try:\n",
    "        with open(filepath, 'w') as f:\n",
    "            for _ in range(count):\n",
    "                num = random.randint(min_val, max_val)\n",
    "                f.write(str(num) + '\\n')\n",
    "                numbers_written += 1\n",
    "                time.sleep(0.02) # Имитация работы\n",
    "        print(f\"[Поток 1 Запись Файла] Файл '{filepath}' заполнен {numbers_written} числами.\")\n",
    "        operations_stats['numbers_generated'] = numbers_written\n",
    "        file_ready_event.set() # Сигнализируем, что файл готов\n",
    "    except IOError as e:\n",
    "        print(f\"[Поток 1 Запись Файла] Ошибка при записи в файл: {e}\")\n",
    "        operations_stats['file_write_errors'] = operations_stats.get('file_write_errors', 0) + 1\n",
    "        # Если файл не создан, другие потоки не должны стартовать.\n",
    "        # Можно было бы не устанавливать событие или использовать другой механизм.\n",
    "\n",
    "\n",
    "def find_primes_in_file(source_filepath: str, result_filepath: str):\n",
    "    \"\"\"\n",
    "    Второй поток: ожидает заполнения файла, находит простые числа, записывает в новый файл.\n",
    "    \"\"\"\n",
    "    global operations_stats\n",
    "    print(f\"[Поток 2 Простые Числа] Ожидание готовности файла '{source_filepath}'...\")\n",
    "    file_ready_event.wait()\n",
    "    print(f\"[Поток 2 Простые Числа] Файл '{source_filepath}' готов. Начинаю поиск простых чисел.\")\n",
    "    \n",
    "    primes_found = 0\n",
    "    numbers_processed = 0\n",
    "    try:\n",
    "        with open(source_filepath, 'r') as sf, open(result_filepath, 'w') as rf:\n",
    "            for line in sf:\n",
    "                try:\n",
    "                    num = int(line.strip())\n",
    "                    numbers_processed += 1\n",
    "                    if is_prime(num):\n",
    "                        rf.write(str(num) + '\\n')\n",
    "                        primes_found += 1\n",
    "                except ValueError:\n",
    "                    print(f\"[Поток 2 Простые Числа] Пропуск нечисловой строки: {line.strip()}\")\n",
    "                    operations_stats['parse_errors_primes'] = operations_stats.get('parse_errors_primes', 0) + 1\n",
    "\n",
    "        print(f\"[Поток 2 Простые Числа] Найдено {primes_found} простых чисел. Результаты в '{result_filepath}'.\")\n",
    "        operations_stats['primes_found'] = primes_found\n",
    "        operations_stats['numbers_processed_by_primes_thread'] = numbers_processed\n",
    "    except IOError as e:\n",
    "        print(f\"[Поток 2 Простые Числа] Ошибка при работе с файлами: {e}\")\n",
    "        operations_stats['file_read_write_errors_primes'] = operations_stats.get('file_read_write_errors_primes', 0) + 1\n",
    "\n",
    "\n",
    "def calculate_factorials_in_file(source_filepath: str, result_filepath: str):\n",
    "    \"\"\"\n",
    "    Третий поток: ожидает заполнения файла, вычисляет факториалы, записывает в новый файл.\n",
    "    \"\"\"\n",
    "    global operations_stats\n",
    "    print(f\"[Поток 3 Факториалы] Ожидание готовности файла '{source_filepath}'...\")\n",
    "    file_ready_event.wait()\n",
    "    print(f\"[Поток 3 Факториалы] Файл '{source_filepath}' готов. Начинаю расчет факториалов.\")\n",
    "\n",
    "    factorials_calculated = 0\n",
    "    numbers_processed = 0\n",
    "    try:\n",
    "        with open(source_filepath, 'r') as sf, open(result_filepath, 'w') as rf:\n",
    "            for line in sf:\n",
    "                try:\n",
    "                    num = int(line.strip())\n",
    "                    numbers_processed += 1\n",
    "                    if 0 <= num <= 20: # Ограничение для факториала, чтобы избежать слишком больших чисел\n",
    "                        fact = factorial(num)\n",
    "                        rf.write(f\"Факториал числа {num} = {fact}\\n\")\n",
    "                        factorials_calculated += 1\n",
    "                    else:\n",
    "                        rf.write(f\"Факториал числа {num} не вычислен (слишком большое или отрицательное).\\n\")\n",
    "                        operations_stats['factorial_skipped_large_negative'] = operations_stats.get('factorial_skipped_large_negative', 0) + 1\n",
    "                except ValueError:\n",
    "                    print(f\"[Поток 3 Факториалы] Пропуск нечисловой строки: {line.strip()}\")\n",
    "                    operations_stats['parse_errors_factorials'] = operations_stats.get('parse_errors_factorials', 0) + 1\n",
    "                except Exception as e_fact: # Ловим ошибки от math.factorial (например, для отрицательных)\n",
    "                    rf.write(f\"Ошибка вычисления факториала для {num}: {e_fact}\\n\")\n",
    "                    operations_stats['factorial_calculation_errors'] = operations_stats.get('factorial_calculation_errors', 0) + 1\n",
    "\n",
    "\n",
    "        print(f\"[Поток 3 Факториалы] Вычислено {factorials_calculated} факториалов. Результаты в '{result_filepath}'.\")\n",
    "        operations_stats['factorials_calculated'] = factorials_calculated\n",
    "        operations_stats['numbers_processed_by_factorials_thread'] = numbers_processed\n",
    "    except IOError as e:\n",
    "        print(f\"[Поток 3 Факториалы] Ошибка при работе с файлами: {e}\")\n",
    "        operations_stats['file_read_write_errors_factorials'] = operations_stats.get('file_read_write_errors_factorials', 0) + 1\n",
    "\n",
    "\n",
    "# --- Основная часть Задания 2 ---\n",
    "operations_stats = {} # Словарь для сбора статистики\n",
    "\n",
    "def run_task2():\n",
    "    print(\"\\n--- Задание 2: Обработка файла в трех потоках ---\")\n",
    "    global operations_stats\n",
    "    operations_stats = { # Сбрасываем статистику перед каждым запуском\n",
    "        'numbers_generated': 0,\n",
    "        'primes_found': 0,\n",
    "        'factorials_calculated': 0,\n",
    "        'numbers_processed_by_primes_thread': 0,\n",
    "        'numbers_processed_by_factorials_thread': 0\n",
    "    }\n",
    "\n",
    "\n",
    "    source_file = input(\"Введите путь к файлу для записи случайных чисел (например, numbers.txt): \")\n",
    "    if not source_file:\n",
    "        source_file = \"numbers_task2.txt\" # Значение по умолчанию\n",
    "        print(f\"Путь не указан, используется файл по умолчанию: {source_file}\")\n",
    "\n",
    "    primes_result_file = \"primes_\" + os.path.basename(source_file)\n",
    "    factorials_result_file = \"factorials_\" + os.path.basename(source_file)\n",
    "\n",
    "    # Удаляем старые файлы результатов, если они существуют\n",
    "    if os.path.exists(primes_result_file): os.remove(primes_result_file)\n",
    "    if os.path.exists(factorials_result_file): os.remove(factorials_result_file)\n",
    "    if os.path.exists(source_file): os.remove(source_file) # И исходный, чтобы каждый раз генерировать заново\n",
    "\n",
    "    # Параметры для генерации чисел в файл\n",
    "    num_count_in_file = 15\n",
    "    min_val_file = 1\n",
    "    max_val_file = 25 # Ограничиваем, чтобы факториалы не были слишком большими\n",
    "\n",
    "    # Сброс события перед новым запуском\n",
    "    file_ready_event.clear()\n",
    "\n",
    "    # Создаем потоки\n",
    "    thread_file_writer = threading.Thread(target=fill_file_with_numbers, \n",
    "                                          args=(source_file, num_count_in_file, min_val_file, max_val_file))\n",
    "    thread_prime_finder = threading.Thread(target=find_primes_in_file, \n",
    "                                           args=(source_file, primes_result_file))\n",
    "    thread_factorial_calculator = threading.Thread(target=calculate_factorials_in_file, \n",
    "                                                   args=(source_file, factorials_result_file))\n",
    "\n",
    "    # Запускаем потоки\n",
    "    thread_file_writer.start()\n",
    "    thread_prime_finder.start()\n",
    "    thread_factorial_calculator.start()\n",
    "\n",
    "    # Ожидаем завершения всех потоков\n",
    "    thread_file_writer.join()\n",
    "    thread_prime_finder.join()\n",
    "    thread_factorial_calculator.join()\n",
    "\n",
    "    # Отображаем статистику\n",
    "    print(\"\\n--- Статистика выполненных операций ---\")\n",
    "    for key, value in operations_stats.items():\n",
    "        print(f\"{key.replace('_', ' ').capitalize()}: {value}\")\n",
    "    \n",
    "    if os.path.exists(source_file):\n",
    "        print(f\"\\nСодержимое исходного файла '{source_file}':\")\n",
    "        try:\n",
    "            with open(source_file, 'r') as f:\n",
    "                print(f.read())\n",
    "        except IOError: print(\"Не удалось прочитать исходный файл.\")\n",
    "            \n",
    "    if os.path.exists(primes_result_file):\n",
    "        print(f\"\\nСодержимое файла с простыми числами '{primes_result_file}':\")\n",
    "        try:\n",
    "            with open(primes_result_file, 'r') as f:\n",
    "                print(f.read())\n",
    "        except IOError: print(\"Не удалось прочитать файл с простыми числами.\")\n",
    "\n",
    "    if os.path.exists(factorials_result_file):\n",
    "        print(f\"\\nСодержимое файла с факториалами '{factorials_result_file}':\")\n",
    "        try:\n",
    "            with open(factorials_result_file, 'r') as f:\n",
    "                print(f.read())\n",
    "        except IOError: print(\"Не удалось прочитать файл с факториалами.\")\n",
    "\n",
    "    print(\"--- Задание 2 Завершено ---\\n\")\n",
    "\n",
    "run_task2() # Раскомментируйте для запуска"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496b2238",
   "metadata": {},
   "source": [
    "Задание 3: Копирование директории в потоке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd0c4db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Задание 3: Копирование директории в потоке ---\n",
      "Ошибка: Не указаны исходная или целевая директория. Используем тестовые значения.\n",
      "Созданы тестовые директории: 'task3_test_area/source_dir_task3' и 'task3_test_area/destination_dir_task3' (пока пустая)\n",
      "[Поток Копирования] Начало копирования из 'task3_test_area/source_dir_task3' в 'task3_test_area/destination_dir_task3'...\n",
      "[Поток Копирования] Создана целевая директория 'task3_test_area/destination_dir_task3'.\n",
      "[Поток Копирования] Копирование поддиректории 'task3_test_area/source_dir_task3/subdir1' в 'task3_test_area/destination_dir_task3/subdir1'...\n",
      "[Поток Копирования] Копирование файла 'task3_test_area/source_dir_task3/file1.txt' в 'task3_test_area/destination_dir_task3/file1.txt'...\n",
      "[Поток Копирования] Копирование файла 'task3_test_area/source_dir_task3/file2.log' в 'task3_test_area/destination_dir_task3/file2.log'...\n",
      "[Поток Копирования] Копирование из 'task3_test_area/source_dir_task3' в 'task3_test_area/destination_dir_task3' завершено.\n",
      "\n",
      "--- Статистика копирования директории ---\n",
      "Время начала: Fri May 23 14:22:51 2025\n",
      "Время окончания: Fri May 23 14:22:51 2025\n",
      "Продолжительность копирования: 0.16 секунд\n",
      "Создано директорий: 2\n",
      "Скопировано файлов: 3\n",
      "Общий размер скопированных файлов: 82 байт (0.00 МБ)\n",
      "--- Задание 3 Завершено ---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Задание 3: Копирование директории в потоке\n",
    "import threading\n",
    "import shutil # Для копирования файлов и директорий\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Глобальная статистика для копирования\n",
    "copy_stats = {\n",
    "    'files_copied': 0,\n",
    "    'dirs_created': 0,\n",
    "    'total_size_copied_bytes': 0,\n",
    "    'errors': 0,\n",
    "    'start_time': 0,\n",
    "    'end_time': 0,\n",
    "}\n",
    "copy_lock = threading.Lock() # Для безопасного обновления статистики\n",
    "\n",
    "def copy_directory_threaded(src_dir: str, dst_dir: str):\n",
    "    \"\"\"\n",
    "    Копирует содержимое директории src_dir в dst_dir, сохраняя структуру.\n",
    "    Эта функция будет выполняться в отдельном потоке.\n",
    "    \"\"\"\n",
    "    global copy_stats\n",
    "    print(f\"[Поток Копирования] Начало копирования из '{src_dir}' в '{dst_dir}'...\")\n",
    "    \n",
    "    with copy_lock:\n",
    "        copy_stats['start_time'] = time.time()\n",
    "\n",
    "    # Проверка существования исходной директории\n",
    "    if not os.path.exists(src_dir):\n",
    "        print(f\"[Поток Копирования] Ошибка: Исходная директория '{src_dir}' не найдена.\")\n",
    "        with copy_lock:\n",
    "            copy_stats['errors'] += 1\n",
    "            copy_stats['end_time'] = time.time()\n",
    "        return\n",
    "    \n",
    "    if not os.path.isdir(src_dir):\n",
    "        print(f\"[Поток Копирования] Ошибка: '{src_dir}' не является директорией.\")\n",
    "        with copy_lock:\n",
    "            copy_stats['errors'] += 1\n",
    "            copy_stats['end_time'] = time.time()\n",
    "        return\n",
    "\n",
    "    # Создаем целевую директорию, если ее нет\n",
    "    # shutil.copytree создает dst_dir, если она не существует.\n",
    "    # Если dst_dir существует, shutil.copytree выбросит FileExistsError,\n",
    "    # поэтому нужно либо удалять ее, либо использовать dirs_exist_ok=True (Python 3.8+)\n",
    "    # или копировать содержимое вручную.\n",
    "    # Для простоты и совместимости, будем копировать содержимое вручную, если dst_dir существует.\n",
    "    \n",
    "    try:\n",
    "        if not os.path.exists(dst_dir):\n",
    "            os.makedirs(dst_dir)\n",
    "            with copy_lock:\n",
    "                copy_stats['dirs_created'] += 1\n",
    "            print(f\"[Поток Копирования] Создана целевая директория '{dst_dir}'.\")\n",
    "\n",
    "        for item_name in os.listdir(src_dir):\n",
    "            src_item_path = os.path.join(src_dir, item_name)\n",
    "            dst_item_path = os.path.join(dst_dir, item_name)\n",
    "\n",
    "            if os.path.isdir(src_item_path):\n",
    "                # Рекурсивно копируем поддиректории (для простоты используем shutil.copytree для поддиректорий)\n",
    "                # или можно реализовать полную рекурсию вручную\n",
    "                print(f\"[Поток Копирования] Копирование поддиректории '{src_item_path}' в '{dst_item_path}'...\")\n",
    "                # shutil.copytree(src_item_path, dst_item_path, dirs_exist_ok=True) # Python 3.8+\n",
    "                \n",
    "                # Ручное рекурсивное копирование для большей совместимости или если dirs_exist_ok недоступен\n",
    "                # В данном случае, так как мы хотим точную статистику, лучше делать это рекурсивно вручную\n",
    "                # или модифицировать статистику после вызова copytree.\n",
    "                # Для этого задания сделаем упрощенно: если это поддиректория, просто рекурсивно вызываем нашу же функцию.\n",
    "                # Это не самый эффективный способ для shutil, но для демонстрации потока и статистики подойдет.\n",
    "                # Однако, чтобы не усложнять, просто скопируем и обновим статистику примерно.\n",
    "                # Или же, для чистоты, будем копировать файлы и создавать директории вручную.\n",
    "                \n",
    "                # Используем shutil.copytree для поддиректорий, если не хотим глубокой ручной рекурсии здесь\n",
    "                # и не так важна точная статистика по поддиректориям внутри этого вызова.\n",
    "                # Для точной статистики лучше сделать полностью ручной обход.\n",
    "                \n",
    "                # Полностью ручной обход:\n",
    "                if not os.path.exists(dst_item_path):\n",
    "                     os.makedirs(dst_item_path)\n",
    "                     with copy_lock:\n",
    "                         copy_stats['dirs_created'] += 1\n",
    "                \n",
    "                # Рекурсивный вызов нашей функции для копирования содержимого поддиректории\n",
    "                # (Это не самый оптимальный путь, но он позволит собрать статистику глубже, если доработать)\n",
    "                # Чтобы не усложнять, просто вызовем копирование файлов внутри этой поддиректории\n",
    "                # и передадим управление копированию файлов.\n",
    "                # Для простоты задания, будем копировать только файлы из корневой src_dir,\n",
    "                # а для поддиректорий используем shutil.copytree (без детальной статистики из него)\n",
    "                # или рекурсивный вызов copy_directory_threaded для поддиректорий (что сделаем).\n",
    "                \n",
    "                # Создадим временный объект потока для рекурсивного копирования поддиректории,\n",
    "                # чтобы статистика корректно собиралась через блокировки.\n",
    "                # Однако, это усложнит.\n",
    "                # Проще всего - передавать copy_stats как аргумент в рекурсивные вызовы.\n",
    "\n",
    "                # Вернемся к более простому варианту для задания:\n",
    "                # Мы будем копировать только файлы верхнего уровня и создавать директории верхнего уровня.\n",
    "                # Глубокое копирование структуры с точной статистикой в одном потоке - это уже сложнее.\n",
    "                # Задание говорит \"скопировать содержимое ... сохранить структуру\".\n",
    "                # shutil.copytree идеально подходит, но тогда статистика будет общей.\n",
    "\n",
    "                # Давайте реализуем ручное копирование с сохранением структуры:\n",
    "                _copy_dir_recursively_with_stats(src_item_path, dst_item_path)\n",
    "\n",
    "\n",
    "            elif os.path.isfile(src_item_path):\n",
    "                print(f\"[Поток Копирования] Копирование файла '{src_item_path}' в '{dst_item_path}'...\")\n",
    "                shutil.copy2(src_item_path, dst_item_path) # copy2 сохраняет метаданные\n",
    "                with copy_lock:\n",
    "                    copy_stats['files_copied'] += 1\n",
    "                    copy_stats['total_size_copied_bytes'] += os.path.getsize(dst_item_path)\n",
    "            time.sleep(0.05) # Имитация работы\n",
    "\n",
    "        print(f\"[Поток Копирования] Копирование из '{src_dir}' в '{dst_dir}' завершено.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[Поток Копирования] Произошла ошибка во время копирования: {e}\")\n",
    "        with copy_lock:\n",
    "            copy_stats['errors'] += 1\n",
    "    finally:\n",
    "        with copy_lock:\n",
    "            copy_stats['end_time'] = time.time()\n",
    "\n",
    "\n",
    "def _copy_dir_recursively_with_stats(src: str, dst: str):\n",
    "    \"\"\"Вспомогательная рекурсивная функция для копирования с обновлением статистики.\"\"\"\n",
    "    global copy_stats\n",
    "    if not os.path.exists(dst):\n",
    "        os.makedirs(dst)\n",
    "        with copy_lock:\n",
    "            copy_stats['dirs_created'] += 1\n",
    "    \n",
    "    for item in os.listdir(src):\n",
    "        s_path = os.path.join(src, item)\n",
    "        d_path = os.path.join(dst, item)\n",
    "        if os.path.isdir(s_path):\n",
    "            _copy_dir_recursively_with_stats(s_path, d_path) # Рекурсивный вызов\n",
    "        else: # Это файл\n",
    "            shutil.copy2(s_path, d_path)\n",
    "            with copy_lock:\n",
    "                copy_stats['files_copied'] += 1\n",
    "                copy_stats['total_size_copied_bytes'] += os.path.getsize(d_path)\n",
    "        time.sleep(0.01) # Имитация\n",
    "\n",
    "\n",
    "# --- Основная часть Задания 3 ---\n",
    "def run_task3():\n",
    "    print(\"\\n--- Задание 3: Копирование директории в потоке ---\")\n",
    "    global copy_stats\n",
    "    copy_stats = { # Сброс статистики\n",
    "        'files_copied': 0,\n",
    "        'dirs_created': 0,\n",
    "        'total_size_copied_bytes': 0,\n",
    "        'errors': 0,\n",
    "        'start_time': 0,\n",
    "        'end_time': 0,\n",
    "    }\n",
    "\n",
    "    source_directory = input(\"Введите путь к существующей директории для копирования: \")\n",
    "    destination_directory = input(\"Введите путь к новой директории (куда копировать): \")\n",
    "\n",
    "    if not source_directory or not destination_directory:\n",
    "        print(\"Ошибка: Не указаны исходная или целевая директория. Используем тестовые значения.\")\n",
    "        # Создадим тестовые директории и файлы для демонстрации\n",
    "        base_test_dir = \"task3_test_area\"\n",
    "        source_directory = os.path.join(base_test_dir, \"source_dir_task3\")\n",
    "        destination_directory = os.path.join(base_test_dir, \"destination_dir_task3\")\n",
    "\n",
    "        # Очистка предыдущих тестовых данных\n",
    "        if os.path.exists(base_test_dir):\n",
    "            shutil.rmtree(base_test_dir)\n",
    "        \n",
    "        os.makedirs(source_directory, exist_ok=True)\n",
    "        os.makedirs(os.path.join(source_directory, \"subdir1\"), exist_ok=True)\n",
    "        with open(os.path.join(source_directory, \"file1.txt\"), \"w\") as f: f.write(\"Это файл 1.\")\n",
    "        with open(os.path.join(source_directory, \"file2.log\"), \"w\") as f: f.write(\"Это файл 2 лог.\")\n",
    "        with open(os.path.join(source_directory, \"subdir1\", \"file3_in_subdir.dat\"), \"w\") as f: f.write(\"Файл в поддиректории.\")\n",
    "        print(f\"Созданы тестовые директории: '{source_directory}' и '{destination_directory}' (пока пустая)\")\n",
    "\n",
    "\n",
    "    # Создаем и запускаем поток\n",
    "    copy_thread = threading.Thread(target=copy_directory_threaded, args=(source_directory, destination_directory))\n",
    "    copy_thread.start()\n",
    "    copy_thread.join() # Ожидаем завершения потока копирования\n",
    "\n",
    "    # Отображаем статистику\n",
    "    print(\"\\n--- Статистика копирования директории ---\")\n",
    "    if copy_stats['errors'] > 0:\n",
    "        print(f\"Во время копирования произошли ошибки: {copy_stats['errors']}\")\n",
    "    \n",
    "    if copy_stats['start_time'] > 0 and copy_stats['end_time'] > 0 : # Если процесс хотя бы начался\n",
    "        duration = copy_stats['end_time'] - copy_stats['start_time']\n",
    "        print(f\"Время начала: {time.ctime(copy_stats['start_time'])}\")\n",
    "        print(f\"Время окончания: {time.ctime(copy_stats['end_time'])}\")\n",
    "        print(f\"Продолжительность копирования: {duration:.2f} секунд\")\n",
    "        print(f\"Создано директорий: {copy_stats['dirs_created']}\")\n",
    "        print(f\"Скопировано файлов: {copy_stats['files_copied']}\")\n",
    "        print(f\"Общий размер скопированных файлов: {copy_stats['total_size_copied_bytes']} байт ({copy_stats['total_size_copied_bytes'] / (1024*1024):.2f} МБ)\")\n",
    "    else:\n",
    "        print(\"Копирование не было запущено или завершилось с критической ошибкой до начала операций.\")\n",
    "\n",
    "    print(\"--- Задание 3 Завершено ---\\n\")\n",
    "\n",
    "run_task3() # Раскомментируйте для запуска"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bd19fd",
   "metadata": {},
   "source": [
    "Задание 4: Поиск слов в файлах и вырезание запрещенных слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa263c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Задание 4: Поиск и цензура в двух потоках ---\n",
      "[Поток 1 Поиск] Начало поиска файлов в '/' по ключевому слову 'да'...\n",
      "[Поток 2 Цензура] Ожидание завершения работы первого потока (слияния файлов)...\n",
      "[Поток 1 Поиск] Найден 'да' в файле: /usr/local/share/nvm/versions/node/v20.19.0/README.md. Содержимое добавлено.\n",
      "[Поток 1 Поиск] Найден 'да' в файле: /usr/local/share/nvm/versions/node/v18.20.7/README.md. Содержимое добавлено.\n",
      "[Поток 1 Поиск] Найден 'да' в файле: /usr/local/share/nvm/versions/node/v18.20.7/lib/node_modules/npm/node_modules/buffer/AUTHORS.md. Содержимое добавлено.\n",
      "[Поток 1 Поиск] Найден 'да' в файле: /usr/share/gnupg/help.ru.txt. Содержимое добавлено.\n",
      "[Поток 1 Поиск] Ошибка чтения файла '/var/log/apt/term.log': [Errno 13] Permission denied: '/var/log/apt/term.log'\n",
      "[Поток 1 Поиск] Найден 'да' в файле: /home/codespace/.vscode-remote/extensions/ms-ceintl.vscode-language-pack-ru-1.100.2025051409/readme.md. Содержимое добавлено.\n",
      "[Поток 1 Поиск] Найден 'да' в файле: /home/codespace/.vscode-remote/data/logs/20250523T112252/exthost6/output_logging_20250523T112808/2-Jupyter.log. Содержимое добавлено.\n",
      "[Поток 1 Поиск] Найден 'да' в файле: /home/codespace/.vscode-remote/data/logs/20250523T112252/exthost7/output_logging_20250523T115542/2-Jupyter.log. Содержимое добавлено.\n",
      "[Поток 1 Поиск] Найден 'да' в файле: /vscode/bin/linux-x64/4b88fa7949c13eea3369e8a05042a03f2f9df8be-insider/node_modules/buffer/AUTHORS.md. Содержимое добавлено.\n",
      "[Поток 1 Поиск] Найден 'да' в файле: /vscode/bin/linux-x64/2d6afddc470bf44f7e60fb5b6e6fdd08e771409b-insider/node_modules/buffer/AUTHORS.md. Содержимое добавлено.\n",
      "[Поток 1 Поиск] Найден 'да' в файле: /vscode/bin/linux-x64/7c6fdfb0b8f2f675eb0b47f3d95eeca78962565b/node_modules/buffer/AUTHORS.md. Содержимое добавлено.\n",
      "[Поток 1 Поиск] Найден 'да' в файле: /vscode/bin/linux-x64/1d7ad01f171443c8b2401f031c2e8f686121515c-insider/node_modules/buffer/AUTHORS.md. Содержимое добавлено.\n",
      "[Поток 1 Поиск] Найден 'да' в файле: /vscode/bin/linux-x64/17baf841131aa23349f217ca7c570c76ee87b957/node_modules/buffer/AUTHORS.md. Содержимое добавлено.\n",
      "[Поток 1 Поиск] Найден 'да' в файле: /vscode/bin/linux-x64/2fc07b811f760549dab9be9d2bedd06c51dfcb9a/node_modules/buffer/AUTHORS.md. Содержимое добавлено.\n",
      "[Поток 1 Поиск] Найден 'да' в файле: /vscode/bin/linux-x64/4949701c880d4bdb949e3c0e6b400288da7f474b/node_modules/buffer/AUTHORS.md. Содержимое добавлено.\n",
      "[Поток 1 Поиск] Найден 'да' в файле: /vscode/bin/linux-x64/848b80aeb52026648a8ff9f7c45a9b0a80641e2e/node_modules/buffer/AUTHORS.md. Содержимое добавлено.\n",
      "[Поток 1 Поиск] Найден 'да' в файле: /vscode/bin/linux-x64/496ebc4723371f29c9ffa0319dcccb2d7bee7ee0-insider/node_modules/buffer/AUTHORS.md. Содержимое добавлено.\n",
      "[Поток 1 Поиск] Найден 'да' в файле: /vscode/bin/linux-x64/ccdd214171190f69e28c8c3def68a6315f4d9ae0-insider/node_modules/buffer/AUTHORS.md. Содержимое добавлено.\n",
      "[Поток 1 Поиск] Найден 'да' в файле: /vscode/bin/linux-x64/6609ac3d66f4eade5cf376d1cb76f13985724bcb/node_modules/buffer/AUTHORS.md. Содержимое добавлено.\n",
      "[Поток 1 Поиск] Найден 'да' в файле: /vscode/bin/linux-x64/4437686ffebaf200fa4a6e6e67f735f3edf24ada/node_modules/buffer/AUTHORS.md. Содержимое добавлено.\n",
      "[Поток 1 Поиск] Найден 'да' в файле: /vscode/bin/linux-x64/18ed64835ec8f8227dbd8562d2d9fd9fa339abbb-insider/node_modules/buffer/AUTHORS.md. Содержимое добавлено.\n",
      "[Поток 1 Поиск] Найден 'да' в файле: /vscode/bin/linux-x64/91fa95bccb027ece6a968589bb1d662fa9c8e170/node_modules/buffer/AUTHORS.md. Содержимое добавлено.\n",
      "[Поток 1 Поиск] Найден 'да' в файле: /vscode/bin/linux-x64/19e0f9e681ecb8e5c09d8784acaa601316ca4571/node_modules/buffer/AUTHORS.md. Содержимое добавлено.\n",
      "[Поток 1 Поиск] Найден 'да' в файле: /vscode/bin/linux-x64/747d0bd66a4699a53e720cf7a61dcd10f664e667-insider/node_modules/buffer/AUTHORS.md. Содержимое добавлено.\n",
      "[Поток 1 Поиск] Найден 'да' в файле: /vscode/bin/linux-x64/17d1fa2d33e93d129c7deff16be86ad360abd2a8-insider/node_modules/buffer/AUTHORS.md. Содержимое добавлено.\n",
      "[Поток 1 Поиск] Найден 'да' в файле: /vscode/bin/linux-x64/6947b69d47deef74e7066f6b18a40a9e2058c8d7-insider/node_modules/buffer/AUTHORS.md. Содержимое добавлено.\n",
      "[Поток 1 Поиск] Найден 'да' в файле: /vscode/bin/linux-x64/ddc367ed5c8936efe395cffeec279b04ffd7db78/node_modules/buffer/AUTHORS.md. Содержимое добавлено.\n",
      "[Поток 1 Поиск] Найден 'да' в файле: /vscode/bin/linux-x64/53524ccad173e498ee03286727e3434fc9d51d5e-insider/node_modules/buffer/AUTHORS.md. Содержимое добавлено.\n",
      "[Поток 1 Поиск] Найден 'да' в файле: /.codespaces/bin/cache/bin/linux-x64/4b88fa7949c13eea3369e8a05042a03f2f9df8be-insider/node_modules/buffer/AUTHORS.md. Содержимое добавлено.\n",
      "[Поток 1 Поиск] Найден 'да' в файле: /.codespaces/bin/cache/bin/linux-x64/2d6afddc470bf44f7e60fb5b6e6fdd08e771409b-insider/node_modules/buffer/AUTHORS.md. Содержимое добавлено.\n",
      "[Поток 1 Поиск] Найден 'да' в файле: /.codespaces/bin/cache/bin/linux-x64/7c6fdfb0b8f2f675eb0b47f3d95eeca78962565b/node_modules/buffer/AUTHORS.md. Содержимое добавлено.\n",
      "[Поток 1 Поиск] Найден 'да' в файле: /.codespaces/bin/cache/bin/linux-x64/1d7ad01f171443c8b2401f031c2e8f686121515c-insider/node_modules/buffer/AUTHORS.md. Содержимое добавлено.\n",
      "[Поток 1 Поиск] Найден 'да' в файле: /.codespaces/bin/cache/bin/linux-x64/17baf841131aa23349f217ca7c570c76ee87b957/node_modules/buffer/AUTHORS.md. Содержимое добавлено.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 231\u001b[39m\n\u001b[32m    226\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e: \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mОшибка чтения файла: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    229\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m--- Задание 4 Завершено ---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m \u001b[43mrun_task4\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Раскомментируйте для запуска\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 208\u001b[39m, in \u001b[36mrun_task4\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    205\u001b[39m thread1_search_merge.start()\n\u001b[32m    206\u001b[39m thread2_censor.start()\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m \u001b[43mthread1_search_merge\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    209\u001b[39m thread2_censor.join()\n\u001b[32m    211\u001b[39m \u001b[38;5;66;03m# Отображаем статистику\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/threading.py:1147\u001b[39m, in \u001b[36mThread.join\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1144\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot join current thread\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1146\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1147\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1148\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1149\u001b[39m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[32m   1150\u001b[39m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[32m   1151\u001b[39m     \u001b[38;5;28mself\u001b[39m._wait_for_tstate_lock(timeout=\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[32m0\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.python/current/lib/python3.12/threading.py:1167\u001b[39m, in \u001b[36mThread._wait_for_tstate_lock\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m   1164\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   1166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1167\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   1168\u001b[39m         lock.release()\n\u001b[32m   1169\u001b[39m         \u001b[38;5;28mself\u001b[39m._stop()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Поток 1 Поиск] Найден 'да' в файле: /.codespaces/bin/cache/bin/linux-x64/2fc07b811f760549dab9be9d2bedd06c51dfcb9a/node_modules/buffer/AUTHORS.md. Содержимое добавлено.\n",
      "[Поток 1 Поиск] Найден 'да' в файле: /.codespaces/bin/cache/bin/linux-x64/4949701c880d4bdb949e3c0e6b400288da7f474b/node_modules/buffer/AUTHORS.md. Содержимое добавлено.\n",
      "[Поток 1 Поиск] Найден 'да' в файле: /.codespaces/bin/cache/bin/linux-x64/848b80aeb52026648a8ff9f7c45a9b0a80641e2e/node_modules/buffer/AUTHORS.md. Содержимое добавлено.\n",
      "[Поток 1 Поиск] Найден 'да' в файле: /.codespaces/bin/cache/bin/linux-x64/496ebc4723371f29c9ffa0319dcccb2d7bee7ee0-insider/node_modules/buffer/AUTHORS.md. Содержимое добавлено.\n",
      "[Поток 1 Поиск] Найден 'да' в файле: /.codespaces/bin/cache/bin/linux-x64/ccdd214171190f69e28c8c3def68a6315f4d9ae0-insider/node_modules/buffer/AUTHORS.md. Содержимое добавлено.\n"
     ]
    }
   ],
   "source": [
    "# Задание 4: Поиск и обработка файлов в двух потоках\n",
    "import threading\n",
    "import os\n",
    "import time\n",
    "import re # Для регулярных выражений (вырезание слов)\n",
    "\n",
    "# Глобальные переменные и объекты синхронизации\n",
    "merged_content_filepath = \"merged_found_files.txt\"\n",
    "banned_words_filepath = \"banned_words.txt\" # Файл с запрещенными словами\n",
    "processed_content_filepath = \"processed_content.txt\"\n",
    "\n",
    "first_thread_done_event = threading.Event()\n",
    "search_replace_stats = {\n",
    "    'files_searched': 0,\n",
    "    'files_matched_keyword': 0,\n",
    "    'total_lines_merged': 0,\n",
    "    'banned_words_loaded': 0,\n",
    "    'words_replaced_count': 0, # Общее количество замен\n",
    "    'search_errors': 0,\n",
    "    'processing_errors': 0\n",
    "}\n",
    "stats_lock = threading.Lock() # Для безопасного обновления статистики\n",
    "\n",
    "# --- Функции для потоков ---\n",
    "def search_and_merge_files(search_dir: str, keyword: str, output_merged_file: str):\n",
    "    \"\"\"\n",
    "    Первый поток: ищет файлы, содержащие ключевое слово, и сливает их содержимое.\n",
    "    \"\"\"\n",
    "    global search_replace_stats\n",
    "    print(f\"[Поток 1 Поиск] Начало поиска файлов в '{search_dir}' по ключевому слову '{keyword}'...\")\n",
    "    \n",
    "    lines_merged_count = 0\n",
    "    files_matched = 0\n",
    "    files_scanned = 0\n",
    "\n",
    "    try:\n",
    "        with open(output_merged_file, 'w', encoding='utf-8') as outfile:\n",
    "            for root, _, files in os.walk(search_dir):\n",
    "                for filename in files:\n",
    "                    if not filename.endswith(('.txt', '.log', '.md')): # Пример фильтрации по типу файлов\n",
    "                        continue \n",
    "                    \n",
    "                    filepath = os.path.join(root, filename)\n",
    "                    files_scanned += 1\n",
    "                    try:\n",
    "                        with open(filepath, 'r', encoding='utf-8', errors='ignore') as infile:\n",
    "                            content = infile.read()\n",
    "                            if keyword.lower() in content.lower(): # Поиск без учета регистра\n",
    "                                files_matched += 1\n",
    "                                outfile.write(f\"\\n--- Содержимое из файла: {filepath} ---\\n\")\n",
    "                                outfile.write(content)\n",
    "                                outfile.write(\"\\n\") # Разделитель между содержимым файлов\n",
    "                                lines_merged_count += content.count('\\n') + 1 # Приблизительное кол-во строк\n",
    "                                print(f\"[Поток 1 Поиск] Найден '{keyword}' в файле: {filepath}. Содержимое добавлено.\")\n",
    "                    except Exception as e_read:\n",
    "                        print(f\"[Поток 1 Поиск] Ошибка чтения файла '{filepath}': {e_read}\")\n",
    "                        with stats_lock: search_replace_stats['search_errors'] +=1\n",
    "                    time.sleep(0.02) # Имитация работы\n",
    "        \n",
    "        with stats_lock:\n",
    "            search_replace_stats['files_searched'] = files_scanned\n",
    "            search_replace_stats['files_matched_keyword'] = files_matched\n",
    "            search_replace_stats['total_lines_merged'] = lines_merged_count\n",
    "        \n",
    "        print(f\"[Поток 1 Поиск] Поиск завершен. Найдено {files_matched} файлов. Результат в '{output_merged_file}'.\")\n",
    "\n",
    "    except IOError as e_write:\n",
    "        print(f\"[Поток 1 Поиск] Критическая ошибка записи в объединенный файл '{output_merged_file}': {e_write}\")\n",
    "        with stats_lock: search_replace_stats['search_errors'] +=1\n",
    "    finally:\n",
    "        first_thread_done_event.set() # Сигнализируем, что первый поток завершил работу\n",
    "\n",
    "\n",
    "def censor_banned_words(source_merged_file: str, banned_list_file: str, output_processed_file: str):\n",
    "    \"\"\"\n",
    "    Второй поток: ожидает завершения первого, читает запрещенные слова,\n",
    "    вырезает их из объединенного файла и сохраняет результат.\n",
    "    \"\"\"\n",
    "    global search_replace_stats\n",
    "    print(f\"[Поток 2 Цензура] Ожидание завершения работы первого потока (слияния файлов)...\")\n",
    "    first_thread_done_event.wait()\n",
    "    \n",
    "    print(f\"[Поток 2 Цензура] Первый поток завершил работу. Начинаю обработку файла '{source_merged_file}'.\")\n",
    "    \n",
    "    banned_words = []\n",
    "    try:\n",
    "        with open(banned_list_file, 'r', encoding='utf-8') as bf:\n",
    "            banned_words = [word.strip().lower() for word in bf if word.strip()]\n",
    "        with stats_lock: search_replace_stats['banned_words_loaded'] = len(banned_words)\n",
    "        print(f\"[Поток 2 Цензура] Загружено {len(banned_words)} запрещенных слов из '{banned_list_file}'.\")\n",
    "    except IOError as e_banned:\n",
    "        print(f\"[Поток 2 Цензура] Ошибка чтения файла запрещенных слов '{banned_list_file}': {e_banned}. Обработка невозможна.\")\n",
    "        with stats_lock: search_replace_stats['processing_errors'] +=1\n",
    "        return\n",
    "\n",
    "    if not banned_words:\n",
    "        print(f\"[Поток 2 Цензура] Список запрещенных слов пуст. Копирование содержимого как есть в '{output_processed_file}'.\")\n",
    "        try:\n",
    "            shutil.copyfile(source_merged_file, output_processed_file)\n",
    "        except Exception as e_copy:\n",
    "             print(f\"[Поток 2 Цензура] Ошибка копирования: {e_copy}\")\n",
    "             with stats_lock: search_replace_stats['processing_errors'] +=1\n",
    "        return\n",
    "\n",
    "    replacements_done = 0\n",
    "    try:\n",
    "        with open(source_merged_file, 'r', encoding='utf-8') as sf, \\\n",
    "             open(output_processed_file, 'w', encoding='utf-8') as pf:\n",
    "            \n",
    "            content_to_process = sf.read()\n",
    "            processed_text = content_to_process\n",
    "            \n",
    "            for word_to_censor in banned_words:\n",
    "                # Используем регулярное выражение для замены целых слов без учета регистра\n",
    "                # \\b - граница слова\n",
    "                # re.IGNORECASE - флаг для игнорирования регистра\n",
    "                # (?i) - встроенный флаг игнорирования регистра для шаблона\n",
    "                # Заменяем на звездочки такой же длины, или на фиксированный плейсхолдер\n",
    "                placeholder = '*' * len(word_to_censor) # или \"[ЦЕНЗУРА]\"\n",
    "                \n",
    "                # pattern = r'\\b' + re.escape(word_to_censor) + r'\\b' # Старый вариант, без игнор кейса в re.sub\n",
    "                # processed_text, num_subs = re.subn(pattern, placeholder, processed_text, flags=re.IGNORECASE)\n",
    "                \n",
    "                # Более простой вариант - пройти по словам и заменить\n",
    "                # Это менее эффективно для больших текстов, чем одно re.sub на все слова,\n",
    "                # но проще для подсчета замен по каждому слову.\n",
    "                # Либо использовать re.subn для подсчета\n",
    "                \n",
    "                # Вариант с re.subn для каждого слова (для подсчета)\n",
    "                temp_text, num_subs_for_word = re.subn(r'\\b' + re.escape(word_to_censor) + r'\\b', \n",
    "                                                       placeholder, \n",
    "                                                       processed_text, \n",
    "                                                       flags=re.IGNORECASE)\n",
    "                if num_subs_for_word > 0:\n",
    "                    processed_text = temp_text\n",
    "                    replacements_done += num_subs_for_word\n",
    "            \n",
    "            pf.write(processed_text)\n",
    "\n",
    "        with stats_lock: search_replace_stats['words_replaced_count'] = replacements_done\n",
    "        print(f\"[Поток 2 Цензура] Обработка завершена. Заменено вхождений запрещенных слов: {replacements_done}. Результат в '{output_processed_file}'.\")\n",
    "\n",
    "    except IOError as e_proc:\n",
    "        print(f\"[Поток 2 Цензура] Ошибка при обработке или записи файла '{output_processed_file}': {e_proc}\")\n",
    "        with stats_lock: search_replace_stats['processing_errors'] +=1\n",
    "\n",
    "# --- Основная часть Задания 4 ---\n",
    "def run_task4():\n",
    "    print(\"\\n--- Задание 4: Поиск и цензура в двух потоках ---\")\n",
    "    global search_replace_stats\n",
    "    search_replace_stats = { # Сброс статистики\n",
    "        'files_searched': 0,\n",
    "        'files_matched_keyword': 0,\n",
    "        'total_lines_merged': 0,\n",
    "        'banned_words_loaded': 0,\n",
    "        'words_replaced_count': 0,\n",
    "        'search_errors': 0,\n",
    "        'processing_errors': 0\n",
    "    }\n",
    "\n",
    "    # Подготовка тестовых данных\n",
    "    test_base_dir = \"task4_search_area\"\n",
    "    if os.path.exists(test_base_dir): shutil.rmtree(test_base_dir) # Очистка\n",
    "    os.makedirs(test_base_dir, exist_ok=True)\n",
    "    \n",
    "    # Создаем файлы для поиска\n",
    "    with open(os.path.join(test_base_dir, \"doc1.txt\"), \"w\", encoding=\"utf-8\") as f: f.write(\"Это первый документ с ключевым словом Python.\\nОчень важный документ.\\nЗапретноеСлово1 тут есть.\")\n",
    "    with open(os.path.join(test_base_dir, \"doc2.md\"), \"w\", encoding=\"utf-8\") as f: f.write(\"Второй файл, тоже про Python.\\nPython это круто! Но есть ЗаПреТноеСлово2.\")\n",
    "    os.makedirs(os.path.join(test_base_dir, \"subdir\"), exist_ok=True)\n",
    "    with open(os.path.join(test_base_dir, \"subdir\", \"doc3.log\"), \"w\", encoding=\"utf-8\") as f: f.write(\"Логи.\\nКлючевое слово Python тут тоже.\\nИ ЗапретноеСлово3.\")\n",
    "    with open(os.path.join(test_base_dir, \"other.dat\"), \"w\", encoding=\"utf-8\") as f: f.write(\"Нетекстовый файл, python тут не ищем.\")\n",
    "    \n",
    "    # Создаем файл с запрещенными словами\n",
    "    global banned_words_filepath\n",
    "    banned_words_filepath = os.path.join(test_base_dir, \"banned_words.txt\")\n",
    "    with open(banned_words_filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"ЗапретноеСлово1\\n\")\n",
    "        f.write(\"запретноеслово2\\n\") # в нижнем регистре для теста\n",
    "        f.write(\"ЗапретноеСлово3\\n\")\n",
    "        f.write(\"слово4\\n\") # Этого слова нет в текстах\n",
    "\n",
    "    # Пути к файлам результатов (будут созданы в текущей директории или test_base_dir)\n",
    "    global merged_content_filepath, processed_content_filepath\n",
    "    merged_content_filepath = os.path.join(test_base_dir, \"merged_found_files.txt\")\n",
    "    processed_content_filepath = os.path.join(test_base_dir, \"processed_content.txt\")\n",
    "    \n",
    "    # Удаляем старые файлы результатов, если они существуют\n",
    "    if os.path.exists(merged_content_filepath): os.remove(merged_content_filepath)\n",
    "    if os.path.exists(processed_content_filepath): os.remove(processed_content_filepath)\n",
    "\n",
    "    # --- Запрос данных от пользователя ---\n",
    "    user_search_dir = input(f\"Введите путь к директории для поиска (Enter для '{test_base_dir}'): \") or test_base_dir\n",
    "    user_keyword = input(\"Введите слово для поиска (Enter для 'Python'): \") or \"Python\"\n",
    "    user_banned_words_file = input(f\"Введите путь к файлу с запрещенными словами (Enter для '{banned_words_filepath}'): \") or banned_words_filepath\n",
    "\n",
    "\n",
    "    first_thread_done_event.clear() # Сброс события\n",
    "\n",
    "    # Создаем и запускаем потоки\n",
    "    thread1_search_merge = threading.Thread(target=search_and_merge_files, \n",
    "                                            args=(user_search_dir, user_keyword, merged_content_filepath))\n",
    "    thread2_censor = threading.Thread(target=censor_banned_words, \n",
    "                                      args=(merged_content_filepath, user_banned_words_file, processed_content_filepath))\n",
    "\n",
    "    thread1_search_merge.start()\n",
    "    thread2_censor.start()\n",
    "\n",
    "    thread1_search_merge.join()\n",
    "    thread2_censor.join()\n",
    "\n",
    "    # Отображаем статистику\n",
    "    print(\"\\n--- Статистика поиска и обработки ---\")\n",
    "    for key, value in search_replace_stats.items():\n",
    "        print(f\"{key.replace('_', ' ').capitalize()}: {value}\")\n",
    "        \n",
    "    if os.path.exists(merged_content_filepath):\n",
    "        print(f\"\\nСодержимое объединенного файла '{merged_content_filepath}' (до цензуры):\")\n",
    "        try:\n",
    "            with open(merged_content_filepath, 'r', encoding='utf-8') as f: print(f.read()[:500] + \"...\") # Первые 500 символов\n",
    "        except Exception as e: print(f\"Ошибка чтения файла: {e}\")\n",
    "            \n",
    "    if os.path.exists(processed_content_filepath):\n",
    "        print(f\"\\nСодержимое обработанного файла '{processed_content_filepath}' (после цензуры):\")\n",
    "        try:\n",
    "            with open(processed_content_filepath, 'r', encoding='utf-8') as f: print(f.read()[:500] + \"...\") # Первые 500 символов\n",
    "        except Exception as e: print(f\"Ошибка чтения файла: {e}\")\n",
    "\n",
    "\n",
    "    print(\"--- Задание 4 Завершено ---\\n\")\n",
    "\n",
    "run_task4() # Раскомментируйте для запуска"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
